{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "\n",
    "\n",
    "The purpose of this project is to build a model, that will be able to distinguish between different seal calls. \n",
    "\n",
    "Grey Seals are known for their wide repertoire of communications which range from clapping [[1]](https://www.smithsonianmag.com/smart-news/first-scientists-film-grey-seals-clapping-show-their-strength-180974133/) to vocalisations so complex that they have been shown to imitate the sounds of vowels and other building blocks of human speech [[2]](https://www.pbs.org/wgbh/nova/article/seals-mimic-speech/).\n",
    "\n",
    "This project will look at specific vocalisations called Rupes and Moans.\n",
    "\n",
    "There are 3 types of rupes A, B and C are distinguished from each other based on frequency, duration and modulation.\n",
    "\n",
    "The dataset used in this stuy comes froma  study into the vocalisations of grey seals off of malin head. [[3]](https://www.mdpi.com/2077-1312/12/1/118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "from matplotlib.colors import LogNorm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Selection           View  Channel  Begin Time (s)  End Time (s)  \\\n",
      "0          1  Spectrogram 1        1      871.984579    872.045877   \n",
      "1          2  Spectrogram 1        1      872.605082    872.730809   \n",
      "2          3  Spectrogram 1        1      873.525329    873.616653   \n",
      "3          4  Spectrogram 1        1      874.776471    874.904325   \n",
      "4          5  Spectrogram 1        1      876.693356    876.876005   \n",
      "\n",
      "   Low Freq (Hz)  High Freq (Hz)  Delta Time (s)  Delta Freq (Hz)  \\\n",
      "0         75.224         426.862          0.0613          351.638   \n",
      "1         42.314         470.151          0.1257          427.837   \n",
      "2         65.821         493.658          0.0913          427.837   \n",
      "3         70.523         441.942          0.1279          371.419   \n",
      "4         47.015         413.733          0.1826          366.718   \n",
      "\n",
      "   Avg Power Density (dB FS/Hz) Annotation  \n",
      "0                        -97.26     Rupe A  \n",
      "1                        -84.86     Rupe A  \n",
      "2                        -90.74     Rupe A  \n",
      "3                        -91.90     Rupe A  \n",
      "4                        -90.45     Rupe A  \n"
     ]
    }
   ],
   "source": [
    "#File index\n",
    "file =  'Samples Grey Seal Data\\Rupes A and B\\\\5713.210809120002'  #from PPT at time 892-896 (Rupe B)\n",
    "#file = 'Guttural rupe\\\\5711.211013040024'\n",
    "#file = 'Rupes A and B\\\\5713.210825190002'\n",
    "#file =          'Moan\\\\5713.210902110002'  #from PPT at time 212 seconds\n",
    "\n",
    "#Read the 2 files\n",
    "sample_rate, samples = wavfile.read(file+'.wav')\n",
    "annot_file_path = file +'.Table.1.selections.txt'\n",
    "\n",
    "#Read the file into a DataFrame\n",
    "df = pd.read_csv(file +'.Table.1.selections.txt', sep='\\t')\n",
    "\n",
    "#Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all rupe call annotation into one dataframe\n",
    "\n",
    "folder = \"Samples Grey Seal Data\\Rupes A and B\"\n",
    "\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "  if file.endswith('.txt'): # only want the annotated files\n",
    "    file_path = os.path.join(folder, file)\n",
    "\n",
    "    # add to dataframe\n",
    "    df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "    combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "combined_df.head(20)\n",
    "\n",
    "#save to CSV\n",
    "combined_df.to_csv('data/project2/combined_rupes_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- 1 https://www.smithsonianmag.com/smart-news/first-scientists-film-grey-seals-clapping-show-their-strength-180974133/\n",
    "- 2 https://www.pbs.org/wgbh/nova/article/seals-mimic-speech/\n",
    "- 3 https://www.mdpi.com/2077-1312/12/1/118\n",
    "- https://towardsdatascience.com/audio-deep-learning-made-simple-part-1-state-of-the-art-techniques-da1d3dff2504\n",
    "- https://medium.com/@okezieowen/audio-deep-learning-in-plain-english-b52843deb64e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
